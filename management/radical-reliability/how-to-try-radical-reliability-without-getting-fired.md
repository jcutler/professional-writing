# How to Try Radical Reliability (Without Getting Fired)

> **Preface**
>
> This piece is a companion to [*Practicing Radical Reliability as a Leader*](management/radical-reliability/radical-reliability.md)
>
> The main essay describes a stance — how to behave reliably inside messy systems. This document focuses on practice: how to try out that stance in real organizations, with real constraints, without confusing integrity and recklessness.
>
> It is grounded primarily in software engineering organizations, where risk, failure, and uncertainty are frequent and visible. It is intentionally cautious. It assumes limited authority, uneven incentives, and the presence of fear — especially around failure, transparency, and AI.

---

Radical Reliability is not a neutral stance.

It changes how information flows, how decisions get made, and who is trusted with judgment. In some organizations, that's welcomed. In others, it's tolerated right up until it isn't.

This piece is about practicing Radical Reliability **carefully** — in ways that reduce risk, build trust, and avoid unnecessary self-immolation.

It's written especially for people who:
- don't control the system,
- still want to act with integrity inside it,
- and don't want to confuse recklessness with courage.

## Start Where You Have Cover

Do not start by challenging leadership narratives in all-hands meetings.

Start where:
- you have direct authority,
- you can absorb consequences,
- and you control the tone and follow-through.

Good starting points:
- one-on-ones with your team
- team retrospectives
- how you respond to mistakes
- how you talk about unfinished work
- how you frame tradeoffs

Radical Reliability spreads through **precedent**, not proclamation.

A lot of leadership advice asks people to be brave: speak up, tell the truth, do the hard thing.

Radical Reliability takes a different approach. It asks how to design systems and behaviors _around you_ so people don't have to rely on bravery just to act responsibly.

### Small, Low-Risk Moves You Can Try

If you're early in your management career, Radical Reliability can sound abstract or risky. However, the goal isn't to overhaul your organization — it's to change the local cost of honesty, repair, and responsibility.

Low-risk moves to start with:

- In a 1:1, explicitly say: "If something feels risky or unclear, I'd rather hear it early than polished."
- When someone brings up a problem, respond first with "thank you for surfacing this early — it gives us more options," before problem-solving.
- In a retro, name one thing you personally got wrong and how you'd repair it.
- When priorities change, explain *why*, even if the reason is uncomfortable or incomplete.
- When using AI, ask "can someone else explain this output?" before shipping it.
- Use timelines to surface risk early, not to promise certainty to your downstream dependencies. It's better to be two weeks late with a month of warning than one week late with none.

These moves don't require permission.
They don't challenge leadership directly.
They slowly change what feels safe to say and do.

### What This Looks Like in Practice

If you're wondering whether you're "doing this right," look for these signals:

- People bring you half-formed concerns instead of fully-defended positions.
- Problems surface earlier, even when the news is uncomfortable.
- Fewer things arrive as emergencies.
- People ask for clarification more often than permission.
- Mistakes are discussed in terms of repair, not blame, and lead to changes that make the mistake harder to repeat and the right action easier to take.

If you're not seeing these yet, that's normal.
They emerge gradually, as people test whether your responses are predictable.

## Make Repair Visible Before You Ask for Risk

If you want people to take risks, they must first see what happens *after* failure.

Before you encourage others to:
- surface problems early,
- share messy drafts,
- or make judgment calls,

_you_ need to:
- admit your own mistakes,
- repair them publicly,
- and demonstrate that nothing terrible happens afterward.

People don't trust encouragement.
They trust **patterns**.

## Sometimes You Have to Spend Trust to Build Trust

There have been times when I've failed **intentionally**.

Not in high-stakes ways where harm was irreversible — but sometimes in situations that mattered, when there was still time to detect, challenge, and repair before real damage occurred.
Not in ways that put customers, peers, or the business at risk.
And never in ways that offload consequences onto someone else.

I've done this most often when onboarding people from low-trust environments — places where failure was discouraged, mistakes were remembered, and "psychological safety" existed mostly in slide decks.

In those environments, saying *"it's safe to fail here"* doesn't work. They've heard that before.

What does work is seeing the full loop:

1. a visible mistake
2. a calm response
3. an explicit repair
4. and no hidden consequences afterward

Sometimes the fastest way to establish that loop is to model it yourself.

That might look like:
- sharing work earlier than you normally would,
- making a decision you expect to revise, or deliberately leaving space for someone else to challenge or improve it,
- or taking responsibility for something messy instead of waiting for clarity.

The point isn't the failure.
The point is the **repair**.

You're showing — not telling — that:
- failure doesn't exile you from competence,
- repair is expected and supported,
- and responsibility doesn't vanish under stress.

This can compress months of guarded behavior into weeks of real trust.

### When *Not* To Do This

Intentional failure is easy to misuse.

Do **not** do this if:
- the stakes are high,
- the blast radius isn't contained,
- others could be blamed or harmed,
- you can't repair immediately,
- or you're doing it for effect.

And never ask others to take a risk you haven't already taken yourself.

The difference between modeling trust and abusing it is simple: **who pays the cost**.

## Truth-Telling Carries Responsibility

Truth-telling with the people you manage requires discipline. The goal is not to eliminate uncertainty, but to make risk and reasoning visible without outsourcing responsibility or inflaming fear.

Truth-telling is safest when it is:
- bounded,
- factual,
- non-performative,
- and tied to outcomes.

Avoid:
- unbounded speculation,
- moral framing,
- or abstract critiques of "the system."

Prefer:
- "Here's what we're seeing."
- "Here's the tradeoff we're making."
- "Here's what we're optimizing for."

## Watch for Warning Signs

Slow down or narrow scope if you see:
- honesty being punished,
- repair quietly discouraged,
- leaders equating realism with negativity,
- requests to "keep things light" during real uncertainty.

These don't always mean stop.
But they do mean **contain**.

## Know When This Won't Work

Radical Reliability will fail in organizations where:
- honesty is structurally punished,
- responsibility is demanded without support,
- dissent is equated with disloyalty,
- failure is remembered but repair is treated as waste rather than value.

In those environments, adaptation may not be the right move.
When the same constraints remain unchanged, they may be telling you something about the system itself.
Recognizing that is sometimes what makes leaving the rational choice.
Exiting is not cynicism.

## AI as a Stress Test for Radical Reliability

Even when the basics are in place, some pressures will still expose the limits of this approach.
AI is one such pressure — not because it creates new problems, but because it **amplifies existing ones**.

It accelerates decision-making, lowers the cost of producing output, and increases uncertainty about value, ownership, and replacement. That makes Radical Reliability harder — and more necessary.

### Fear Changes Behavior Before Outcomes Change

You don't need to believe AI will replace jobs to see its effects.

People already act as if it might.

That fear shows up as:
- hoarding context,
- optimizing for visible output,
- reluctance to admit uncertainty,
- deferring responsibility to tools.

Radical Reliability doesn't dismiss this fear.
It doesn't speculate about outcomes.
And it doesn't offer false reassurance.

It **names the fear** and treats it as a real factor shaping behavior.

Ignoring it just drives it underground.

### AI Makes Slop Cheap and Legibility Expensive

AI dramatically lowers the cost of producing work that *looks* finished.

That's not neutral.

Code that can't be explained.
Decisions that can't be traced.
Output that can't be repaired.

This kind of slop is more dangerous than unfinished work, because it hides uncertainty instead of surfacing it.

Radical Reliability prefers:
- visible thinking over polished output,
- explainable decisions over black boxes,
- repairable systems over impressive demos.

Speed without legibility is fragility.

It makes systems harder to understand, harder to maintain, and harder to safely build on — especially as AI use increases.

### Tools Don't Hold Responsibility — People Do

"The model suggested it" is not an acceptable end to a decision.

AI can assist judgment.
It cannot absorb accountability.

If responsibility dissolves when tools are involved, then responsibility never really existed in the first place.

Radical Reliability insists that:
- humans remain accountable for outcomes,
- tools do not hold blame,
- and judgment cannot be outsourced.

AI tests whether you actually meant what you said about ownership.

### Using AI Without Undermining Trust

Some practical constraints that help:

- Use AI where it increases legibility, not obscurity.
- Treat AI output as draft material, not authority.
- Require explainability proportional to impact.
- Be explicit about where AI was used.
- Never let AI be the reason no one owns a decision.

AI should shorten feedback loops — not erase them.

## A Useful Rule of Thumb

If you want to practice Radical Reliability safely:

**Never ask others to take a risk you wouldn't take yourself — and never ask them to carry a consequence you won't absorb.**

That rule will keep you out of most trouble.

## In Closing

Radical Reliability isn't about bravery.

It's about choosing clarity over comfort, repair over blame, and dignity over control — **within the constraints you actually face**.

Some organizations will grow stronger when you do this.
Some will tolerate it.
Some will quietly push you out.

Pay attention to which one you're in.

And remember:
if an organization cannot tolerate people acting responsibly with good information and honest intent, that's not a personal failure.

It's a signal.
